{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "balanced_dataset_generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_O_aC2MBwBJ"
      },
      "source": [
        "# Descargamos el dataset\n",
        "# !gdown --id 1u1MRRWnjoi3p5eWV6bOtJX4_bZ0DT4eu\n",
        "# !unzip balanced_dataset.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddO74_HICsqE"
      },
      "source": [
        "# Librerias utilizadas.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Input,MaxPooling2D, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts74D_dYLFB9"
      },
      "source": [
        "\n",
        "# Generador de datos\n",
        "class DataGenerator(Sequence):\n",
        "\n",
        "  # imgIDs: Lista de las ID de las imagenes a utilizar en este generator.\n",
        "  # labels: Diccionario de los labels para cada ID (sin one hot encoding)\n",
        "  # batch_size: Tama√±o de cada batch que se genera por llamado.\n",
        "  # dim: Dimensiones de las imagenes.\n",
        "  # n_channels: Numero de canales de la imagen.\n",
        "  # n_classes: Numero de labels distintos.\n",
        "  # shuffle: Si revolver los datos o no.\n",
        "  def __init__(self, imgIDs, labels, batch_size=32, dim=(180, 320), n_channels=3, n_classes=4, shuffle=True):\n",
        "    self.imgIDs = imgIDs\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.dim = dim\n",
        "    self.n_channels = n_channels\n",
        "    self.n_classes = n_classes\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  # Retorna el numero de batches del generator.\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.imgIDs) / self.batch_size))\n",
        "\n",
        "  # Retorna un batch.\n",
        "  def __getitem__(self, index):\n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "    list_IDs_temp = [self.imgIDs[k] for k in indexes]\n",
        "    X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  # Cuando se termina un epoch, se escogen los siguientes ID.\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(len(self.imgIDs))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  # Se cargan los datos a medida que se necesitan.\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "    X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "    y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "    for i, ID in enumerate(list_IDs_temp):\n",
        "      X[i,] = io.imread(\"./balanced_dataset_medium/data/\" + ID + \".jpg\")\n",
        "      y[i] = self.labels[ID]\n",
        "    \n",
        "    X = X.astype(\"float32\") / 255\n",
        "\n",
        "    return X, to_categorical(y, num_classes=self.n_classes)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLfKntP8C5ZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d2500adb-9844-451a-cbdc-ff6b19be4d69"
      },
      "source": [
        "# Observamos los datos del CSV.\n",
        "dataInfo = pd.read_csv(\"./balanced_dataset_medium/data_info.csv\")\n",
        "dataInfo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>part</th>\n",
              "      <th>label</th>\n",
              "      <th>views</th>\n",
              "      <th>comments</th>\n",
              "      <th>likes</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>topicID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>id---2pGwkL7M_video</td>\n",
              "      <td>part1</td>\n",
              "      <td>0</td>\n",
              "      <td>3543</td>\n",
              "      <td>11.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['/m/04rlf', '/m/04rlf']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>id---9beuLW7Y_video</td>\n",
              "      <td>part1</td>\n",
              "      <td>0</td>\n",
              "      <td>1543</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['/m/098wr', '/m/098wr']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>id---dQKphvYc_video</td>\n",
              "      <td>part1</td>\n",
              "      <td>0</td>\n",
              "      <td>4065</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['/m/04rlf', '/m/064t9']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>id---EnHBffak_video</td>\n",
              "      <td>part1</td>\n",
              "      <td>0</td>\n",
              "      <td>7808</td>\n",
              "      <td>5.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>['/m/0bzvm2', '/m/0bzvm2']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>id---FI9JLZRg_video</td>\n",
              "      <td>part1</td>\n",
              "      <td>0</td>\n",
              "      <td>1308</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['/m/0bzvm2', '/m/0bzvm2', '/m/0403l3g']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19980</th>\n",
              "      <td>19980</td>\n",
              "      <td>idE2gK1mLbJKE_video</td>\n",
              "      <td>part189</td>\n",
              "      <td>3</td>\n",
              "      <td>3547841</td>\n",
              "      <td>460.0</td>\n",
              "      <td>16357.0</td>\n",
              "      <td>777.0</td>\n",
              "      <td>['/m/04rlf', '/m/01lyv']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19981</th>\n",
              "      <td>19981</td>\n",
              "      <td>ide2hvBdWy0X8_video</td>\n",
              "      <td>part189</td>\n",
              "      <td>3</td>\n",
              "      <td>1414097</td>\n",
              "      <td>568.0</td>\n",
              "      <td>8945.0</td>\n",
              "      <td>385.0</td>\n",
              "      <td>['/m/04rlf', '/m/064t9', '/m/0glt670']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19982</th>\n",
              "      <td>19982</td>\n",
              "      <td>ide2jPLqvMRwM_video</td>\n",
              "      <td>part189</td>\n",
              "      <td>3</td>\n",
              "      <td>1884647</td>\n",
              "      <td>112.0</td>\n",
              "      <td>2071.0</td>\n",
              "      <td>853.0</td>\n",
              "      <td>['/m/04rlf']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19983</th>\n",
              "      <td>19983</td>\n",
              "      <td>ide2JR9LtAic0_video</td>\n",
              "      <td>part189</td>\n",
              "      <td>3</td>\n",
              "      <td>1459441</td>\n",
              "      <td>3169.0</td>\n",
              "      <td>20779.0</td>\n",
              "      <td>386.0</td>\n",
              "      <td>['/m/025zzc', '/m/0bzvm2', '/m/0bzvm2', '/m/02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19984</th>\n",
              "      <td>19984</td>\n",
              "      <td>ide2lDHnV9P1Y_video</td>\n",
              "      <td>part189</td>\n",
              "      <td>3</td>\n",
              "      <td>3901321</td>\n",
              "      <td>47.0</td>\n",
              "      <td>2068.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>['/m/02jjt', '/m/02jjt', '/m/02vxn']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19985 rows √ó 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                            topicID\n",
              "0               0  ...                           ['/m/04rlf', '/m/04rlf']\n",
              "1               1  ...                           ['/m/098wr', '/m/098wr']\n",
              "2               2  ...                           ['/m/04rlf', '/m/064t9']\n",
              "3               3  ...                         ['/m/0bzvm2', '/m/0bzvm2']\n",
              "4               4  ...           ['/m/0bzvm2', '/m/0bzvm2', '/m/0403l3g']\n",
              "...           ...  ...                                                ...\n",
              "19980       19980  ...                           ['/m/04rlf', '/m/01lyv']\n",
              "19981       19981  ...             ['/m/04rlf', '/m/064t9', '/m/0glt670']\n",
              "19982       19982  ...                                       ['/m/04rlf']\n",
              "19983       19983  ...  ['/m/025zzc', '/m/0bzvm2', '/m/0bzvm2', '/m/02...\n",
              "19984       19984  ...               ['/m/02jjt', '/m/02jjt', '/m/02vxn']\n",
              "\n",
              "[19985 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbDKC77ADJhZ"
      },
      "source": [
        "# Tama√±o de los grupos, donde se indica con proporciones.\n",
        "# El resto se le asigna al grupo de test.\n",
        "trainSize = 0.6\n",
        "valSize = 0.2\n",
        "\n",
        "# Generamos el diccionario de los labels, y cargamos todos los IDs en una lista.\n",
        "labels = {}\n",
        "data = []\n",
        "\n",
        "for i, row in dataInfo.iterrows():\n",
        "  data.append(row[\"ID\"])\n",
        "  labels[row[\"ID\"]] = row[\"label\"]\n",
        "\n",
        "# Revolvemos la lista de ID.\n",
        "random.Random(42).shuffle(data)\n",
        "\n",
        "# Generamos las listas de IDs para cada grupo.\n",
        "trainData = data[:int(len(data)*trainSize)]\n",
        "valData = data[int(len(data)*trainSize) : int(len(data)*trainSize) + int(len(data)*valSize)]\n",
        "testData = data[int(len(data)*trainSize) + int(len(data)*valSize):]\n",
        "\n",
        "# Creamos el diccionario de listas de ID para cada grupo.\n",
        "partition = {}\n",
        "partition[\"train\"] = trainData\n",
        "partition[\"validation\"] = valData\n",
        "partition[\"test\"] = testData"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq0ZQnPOFjzq"
      },
      "source": [
        "# TODO: Graficar una wea"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlDHz15cMvhR"
      },
      "source": [
        "# Creamos los generadores.\n",
        "trainGenerator = DataGenerator(partition[\"train\"], labels)\n",
        "valGenerator = DataGenerator(partition[\"validation\"], labels)\n",
        "testGenerator = DataGenerator(partition[\"test\"], labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd8XZJ86HiUs"
      },
      "source": [
        "# # Creamos la red y la compilamos.\n",
        "# model = Sequential()\n",
        "# #Conv 1\n",
        "# model.add(Conv2D(96, kernel_size=(11, 11), activation='relu', input_shape=(180,320,3)))\n",
        "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "# #Conv 2\n",
        "# model.add(Conv2D(256, kernel_size=(5, 5), activation=\"relu\"))\n",
        "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "# #Conv 3\n",
        "# model.add(Conv2D(384, kernel_size=(3, 3), activation=\"relu\"))\n",
        "\n",
        "# #Conv 4\n",
        "# model.add(Conv2D(384, kernel_size=(3, 3), activation=\"relu\"))\n",
        "\n",
        "# #Conv 5\n",
        "# model.add(Conv2D(256, kernel_size=(3, 3), activation=\"relu\"))\n",
        "# model.add(Dropout(0.50))\n",
        "\n",
        "# model.add(Flatten())\n",
        "\n",
        "# #FC 1\n",
        "# model.add(Dense(4096, activation=\"relu\"))\n",
        "# model.add(Dropout(0.50))\n",
        "\n",
        "# #FC 2\n",
        "# model.add(Dense(4096, activation=\"relu\"))\n",
        "# model.add(Dropout(0.50))\n",
        "\n",
        "# model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(180,320,3)))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.50))\n",
        "model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "#funcion para ir ajustando el learning rate durante el entrenamiento\n",
        "def scheduler(epoch):\n",
        "    if epoch < 30:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.0001 * tf.math.exp(0.1 * (10 - epoch))\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.001)\n",
        "#callback de la funcion para ajustar el learning rate\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "#callback para guardar los pesos de la epoch con mejor resultado de perdida en el set de validacion\n",
        "checkpoint = ModelCheckpoint('covid_cnn_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode = 'auto')\n",
        "#callback de early stopping con paciencia hasta 8 epocas\n",
        "stopping = EarlyStopping(monitor='val_loss', patience=8)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjUoaT3bA8Iz"
      },
      "source": [
        "# import os, cv2\n",
        "# img_folder = './balanced_dataset_medium/data/'\n",
        "# n = 10000\n",
        "# x_train = []\n",
        "# y_train = []\n",
        "# for file in dataInfo[\"ID\"][:10000]:\n",
        "#   image_path = os.path.join(img_folder, file+\".jpg\") #ruta de imagen\n",
        "#   image = cv2.imread(image_path) #lectura de imagen\n",
        "#   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#   image = np.array(image) #se transforma a un numpy array para que sirva de input para la red\n",
        "#   image = image.astype('float32')\n",
        "#   image /= 255 #estandarizaci√≥n de imagen\n",
        "#   x_train.append(image)\n",
        "#   y_train.append(dataInfo.query(\"ID == @file\")['label'].item())\n",
        "#   #views = dataInfo.query(\"ID == @file\")['views']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdzJ_TOVtTBv"
      },
      "source": [
        "# for i in range(len(x_train)):\n",
        "#   x_train[i] = np.array(x_train[i])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C81xQqV3B-Dk"
      },
      "source": [
        "#x_train = np.array(x_train,dtype=np.uint16)\n",
        "# x_train = np.array(x_train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5EPr7nSP3U8"
      },
      "source": [
        "# x_axis = [\"<10000\", \"<100k\", \"<1kk\", \">1kk\"]\n",
        "# y_axis = [y_train.count(0),y_train.count(1),y_train.count(2),y_train.count(3)]\n",
        "# print(y_axis[0],y_axis[1],y_axis[2],y_axis[3])\n",
        "# plt.bar(x_axis, y_axis, width = 0.4)\n",
        "# plt.title(\"YT-8M dataset balanced(?\")\n",
        "# plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE6QHMT3rV5Y"
      },
      "source": [
        "# y_train = np.array(y_train)\n",
        "# print(y_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PhcWk-typCZ"
      },
      "source": [
        "#y_train = keras.utils.to_categorical(y_train, 4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6jW7p29ob0J"
      },
      "source": [
        "#plt.imshow(x_train[1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQv8gWibJsZO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "e75a2942-70ef-4cb4-e3a2-e4affffb0070"
      },
      "source": [
        "# Entrenamos la red.\n",
        "# El steps_per_epoch indica cuantos batches del train son un epoch.\n",
        "# El validation_steps es lo mismo pero para el validation.\n",
        "history = model.fit(trainGenerator, validation_data=valGenerator, epochs=100, callbacks = [stopping, lr_schedule, reduce_lr])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "374/374 [==============================] - 102s 259ms/step - loss: 1.3869 - accuracy: 0.2523 - val_loss: 1.3861 - val_accuracy: 0.2513\n",
            "Epoch 2/100\n",
            "374/374 [==============================] - 99s 264ms/step - loss: 1.3868 - accuracy: 0.2589 - val_loss: 1.3860 - val_accuracy: 0.2497\n",
            "Epoch 3/100\n",
            "301/374 [=======================>......] - ETA: 17s - loss: 1.3861 - accuracy: 0.2646"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-94c762483650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# El steps_per_epoch indica cuantos batches del train son un epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# El validation_steps es lo mismo pero para el validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}